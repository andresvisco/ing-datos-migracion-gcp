# GuÃ­a de nomenclatura para la plataforma de datos de MEDICUS en GCP

> Proyecto: `ing-datos-migracion-gcp`

Esta guÃ­a define las convenciones de nombres y etiquetas para los recursos de Google Cloud Platform utilizados en la migraciÃ³n del Ã¡rea de datos de MEDICUS. El objetivo es facilitar la trazabilidad, operaciÃ³n y gobernanza multientorno (dev, qa, prod) y multidominio.

## Principios generales

- **Estructura base**: `<empresa>-<plataforma>-<dominio>-<componente>-<entorno>-<regiÃ³n>-<sufijoOpcional>`
- **Separadores**: guion medio `-`. Evitar guiones bajos y mayÃºsculas.
- **Longitud**: respetar lÃ­mites de cada servicio (por ejemplo, buckets â‰¤ 63 caracteres, BigQuery datasets â‰¤ 1024 caracteres, etc.).
- **Formato**: usar minÃºsculas; para identificadores con restricciones (BigQuery tablas, columnas) utilizar `snake_case`.
- **Entornos** estÃ¡ndar: `dev`, `qa`, `prod`. Se puede contemplar `sandbox` o `dr` si aplica.
- **Dominios funcionales** (ejemplos): `cli` (clientes), `opr` (operaciones), `fin` (financiero), `mkt` (marketing). Ajustar segÃºn catÃ¡logo de datos.
- **Componentes abreviados**:
  - `raw` / `stg` / `cur` / `pub`: capas de datos (bronze, silver, gold, publish).
  - `bq`, `gcs`, `spn`, `df`, `ps`, `cmp`, `sa`: BigQuery, Cloud Storage, Spanner, Dataflow, Pub/Sub, Composer, Service Account.

## Etiquetas y anotaciones

Aplicar etiquetas (`labels`) comunes en los recursos que lo permitan:

| Clave          | Valor sugerido                         | DescripciÃ³n                             |
|----------------|----------------------------------------|-----------------------------------------|
| `project`      | `ing-datos-migracion-gcp`              | Proyecto paraguas                       |
| `business_unit`| `medicus-data`                         | Unidad responsable                      |
| `environment`  | `dev` \| `qa` \| `prod`                | Entorno de despliegue                   |
| `domain`       | `<dominio>`                            | Dominio de datos                        |
| `managed_by`   | `terraform` \| `manual`                | Origen del recurso                      |
| `owner`        | `data-platform`                        | Equipo responsable                      |

## Proyectos y carpetas

- **Proyectos GCP**: `medicus-data-<entorno>` (por ejemplo `medicus-data-prod`).
- **Folders (opcional)**: `medicus-data/<entorno>` para organizar polÃ­ticas IAM y facturaciÃ³n.

## Almacenamiento: Cloud Storage

- **Buckets landing/raw**: `medicus-data-raw-<dominio>-<entorno>-<region>` â†’ ej. `medicus-data-raw-cli-prod-us`
- **Buckets staging**: `medicus-data-stg-<dominio>-<entorno>-<region>`
- **Buckets curated/publicados**: `medicus-data-cur-<dominio>-<entorno>-<region>` y `medicus-data-pub-<dominio>-<entorno>-<region>`
- **Buckets temporales Dataflow**: `medicus-data-df-tmp-<entorno>-<region>`
- **Buckets templates Dataflow**: `medicus-data-df-tpl-<entorno>-<region>`

Reglas: los buckets son globales, validar unicidad y longitud. Para `region`, usar cÃ³digo corto (`us`, `us-central1`, `sa-east1`) segÃºn necesidad.

### Formato de archivos en Cloud Storage

**Formato principal: Parquet**

Para la zona Bronze, el formato estÃ¡ndar es **Parquet** debido a sus ventajas:

- **CompresiÃ³n columnar**: Reduce el tamaÃ±o de almacenamiento significativamente.
- **Lectura eficiente**: BigQuery y Dataflow pueden leer solo las columnas necesarias.
- **PreservaciÃ³n de tipos**: Mantiene tipos de datos nativos (int, float, timestamp, etc.).
- **Compatibilidad**: Soporte nativo en todo el stack GCP (BigQuery, Dataflow, Spark).

**Convenciones de nombres de archivos Parquet:**

- Usar particionamiento por fecha cuando sea posible: `fecha=YYYY-MM-DD/data.parquet`
- Incluir prefijo descriptivo: `{source_system}_{tabla}_{timestamp}.parquet`
- Ejemplo: `qlikview_clientes_20240115_120000.parquet`

**Formato alternativo: Avro**

Usar Avro solo cuando:
- Se requiera evoluciÃ³n de esquema dinÃ¡mica
- Los datos provengan de streaming (Pub/Sub, Kafka)
- Exista compatibilidad legacy con sistemas existentes

## BigQuery

- **Datasets por capa**: `medicus_<layer>_<dominio>_<entorno>` â†’ ej. `medicus_bronze_cli_prod`
- **Tablas**: `layer_dom_usuario`, usar `snake_case` (ej. `bronze_cli_historial_visitas`).
- **Views**: prefijo `vw_` (ej. `vw_cli_resumen_prod`).
- **Routines/UDFs**: prefijo `fn_`.
- **Proyectos para analytics** (si se separan): `medicus-bq-<entorno>`.

## Cloud Spanner

- **Instancia**: `medicus-spn-<dominio>-<entorno>` â†’ ej. `medicus-spn-cli-prod`
- **Base de datos**: `db_<dominio>_<proposito>` â†’ ej. `db_cli_cuentas`
- **Esquemas**: tablas en `snake_case` y columnas en `snake_case`.

## Dataflow

- **Service Account**: `sa-df-<dominio>-<entorno>@<project>.iam.gserviceaccount.com`
- **Jobs**: `df-<pipeline>-<dominio>-<entorno>` â†’ ej. `df-bronze-to-silver-cli-prod`
- **Plantillas (GCS)**: ubicadas en `medicus-data-df-tpl-<entorno>-<region>/pipelines/<pipeline>.json`
- **Stages temporales**: `medicus-data-df-tmp-<entorno>-<region>/jobs/<pipeline>/`

## Pub/Sub

- **Topics**: `ps-<dominio>-<evento>-<entorno>` â†’ ej. `ps-cli-alta-socio-prod`
- **Subscriptions**: `ps-<dominio>-<evento>-<consumer>-<entorno>` â†’ ej. `ps-cli-alta-socio-df-silver-prod`

## OrquestaciÃ³n (Cloud Composer / Workflows)

- **Composer environment**: `cmp-data-<entorno>` â†’ ej. `cmp-data-qa`
- **DAGs / Workflows**: `dag_<pipeline>_<dominio>_<entorno>`
- **Buckets Composer**: `medicus-data-cmp-<entorno>-<region>`

## IAM Service Accounts genÃ©ricas

- Formato: `sa-<componente>-<dominio>-<entorno>@<project>.iam.gserviceaccount.com`
- Ejemplos: `sa-bq-cli-prod`, `sa-spn-fin-qa`

## Secret Manager

- **Secretos**: `sec-<componente>-<dominio>-<entorno>-<descripcion>` â†’ `sec-spn-cli-prod-credentials`
- **Versiones**: mantener etiqueta `stage` y `owner`.

## Artifact Registry / Contenedores

- **Repositorio**: `<region>-docker.pkg.dev/medicus-data-platform/<dominio>/<app>-<entorno>`
- **ImÃ¡genes**: `<app>-<version>` con tags semÃ¡nticos.

## Cloud Logging & Monitoring

- **Logs-based metrics**: `lbm_<dominio>_<proposito>_<entorno>`
- **Alerting policies**: `alert_<dominio>_<proposito>_<entorno>`

## Ejemplo completo

Para un pipeline que ingiere informaciÃ³n de clientes (dominio `cli`) desde sistemas legacy a capa bronze y luego a silver en `prod`:

| Recurso                        | Nombre sugerido                                         |
|--------------------------------|----------------------------------------------------------|
| Bucket landing                 | `medicus-data-raw-cli-prod-us`                           |
| Bucket staging                 | `medicus-data-stg-cli-prod-us`                           |
| Dataset BigQuery bronze        | `medicus_bronze_cli_prod`                                |
| Dataset BigQuery silver        | `medicus_silver_cli_prod`                                |
| Job Dataflow bronzeâ†’silver     | `df-bronze-to-silver-cli-prod`                           |
| Topic Pub/Sub eventos cliente  | `ps-cli-alta-socio-prod`                                 |
| Spanner instance               | `medicus-spn-cli-prod`                                   |
| Spanner database               | `db_cli_master`                                          |
| Service account Dataflow       | `sa-df-cli-prod@medicus-data-prod.iam.gserviceaccount.com` |
| Composer environment           | `cmp-data-prod`                                          |

## Ejemplo configuraciÃ³n entorno DEV

ConfiguraciÃ³n del entorno de desarrollo con datos exportados desde QlikView en formato Parquet:

| Recurso                        | Nombre utilizado                                         | Notas                                    |
|--------------------------------|----------------------------------------------------------|------------------------------------------|
| **Proyecto GCP**               | `medicus-data-dataml-dev`                                | Proyecto principal del entorno dev       |
| **Bucket Bronze (RAW)**        | `medicus-data-bronze-raw-dev-uscentral1`                 | Almacena archivos Parquet de QlikView    |
| **Dataset BigQuery Bronze**    | `medicus_bronze_raw_acumulado`                           | Dataset acumulado en proyecto dev        |
| **Dataset completo**           | `medicus-data-dataml-dev.medicus_bronze_raw_acumulado`   | Referencia completa para consultas       |
| **Formato de archivos**        | **Parquet**                                              | Optimizado para BigQuery y Dataflow      |
| **Job Dataflow ingesta**       | `df-qlikview-to-bronze-dev`                              | Pipeline de ingesta desde QlikView       |
| **Service Account Dataflow**   | `sa-df-bronze-dev@medicus-data-dataml-dev.iam.gserviceaccount.com` | SA para pipelines de Bronze      |
| **Composer environment**       | `cmp-data-dev`                                           | Orquestador Airflow para dev             |
| **Bucket Composer**            | `medicus-data-cmp-dev-uscentral1`                        | Bucket asociado a Composer               |

### Estructura de archivos en Bronze (DEV)

Los archivos Parquet exportados desde QlikView se organizan en el bucket Bronze siguiendo esta estructura:

```
gs://medicus-data-bronze-raw-dev-uscentral1/
â”œâ”€â”€ qlikview_exports/
â”‚   â”œâ”€â”€ tabla1/
â”‚   â”‚   â”œâ”€â”€ fecha=2024-01-01/
â”‚   â”‚   â”‚   â””â”€â”€ data.parquet
â”‚   â”‚   â””â”€â”€ fecha=2024-01-02/
â”‚   â”‚       â””â”€â”€ data.parquet
â”‚   â”œâ”€â”€ tabla2/
â”‚   â”‚   â””â”€â”€ fecha=2024-01-01/
â”‚   â”‚       â””â”€â”€ data.parquet
â”‚   â””â”€â”€ _metadata/
â”‚       â””â”€â”€ export_log.json
â””â”€â”€ staging/
    â””â”€â”€ temp/
```

### Etiquetas aplicadas en DEV

Todos los recursos del entorno dev incluyen las siguientes etiquetas para gobernanza:

```yaml
labels:
  project: "ing-datos-migracion-gcp"
  business_unit: "medicus-data"
  environment: "dev"
  domain: "bronze-raw"
  managed_by: "terraform"
  owner: "data-platform"
  data_format: "parquet"
  source_system: "qlikview"
```

## PrÃ³ximos pasos sugeridos

1. **ValidaciÃ³n y Compliance**: Validar con seguridad, networking y compliance para detectar restricciones adicionales (nombres reservados, longitud).
2. **IntegraciÃ³n con Terraform**: Incorporar la convenciÃ³n en los mÃ³dulos Terraform y plantillas CI/CD para garantizar automatizaciÃ³n completa.
3. **Matriz de Dominios**: Mantener una matriz de dominios y owners para asegurar consistencia al crear nuevos recursos.
4. **ValidaciÃ³n Automatizada**: Ejecutar `validate_nomenclatura.py` en todos los pipelines CI/CD antes de despliegues.
5. **DocumentaciÃ³n de Linaje**: Registrar todos los flujos de datos en Data Catalog para trazabilidad completa.
6. **AuditorÃ­a Regular**: Revisar trimestralmente el cumplimiento de nomenclatura en todos los recursos existentes.
7. **CapacitaciÃ³n del Equipo**: Asegurar que todos los miembros del equipo conozcan y apliquen estas convenciones.

## Principios de Gobernanza

### MÃ¡ximos EstÃ¡ndares de Calidad

Todas las nomenclaturas y recursos deben cumplir con:

- âœ… **Consistencia**: Mismas reglas en dev, qa y prod
- âœ… **Trazabilidad**: Nombres que permitan identificar propÃ³sito, dominio y entorno
- âœ… **AutomatizaciÃ³n**: ValidaciÃ³n en CI/CD para prevenir errores
- âœ… **Modularidad**: Estructura que facilite reutilizaciÃ³n y mantenimiento
- âœ… **DocumentaciÃ³n**: Cada recurso debe tener propÃ³sito y owner claramente definidos
- âœ… **Seguridad**: Nomenclatura que facilite aplicaciÃ³n de polÃ­ticas IAM granulares

### Etiquetas Obligatorias para Gobernanza

Todos los recursos GCP **deben** incluir estas etiquetas sin excepciÃ³n:

| Etiqueta | Obligatoria | Valores Permitidos | PropÃ³sito |
|----------|-------------|-------------------|-----------|
| `project` | âœ… SÃ­ | `ing-datos-migracion-gcp` | IdentificaciÃ³n del proyecto paraguas |
| `business_unit` | âœ… SÃ­ | `medicus-data` | Unidad de negocio responsable |
| `environment` | âœ… SÃ­ | `dev`, `qa`, `prod` | Entorno de despliegue |
| `domain` | âœ… SÃ­ | `cli`, `fin`, `opr`, etc. | Dominio funcional de datos |
| `managed_by` | âœ… SÃ­ | `terraform`, `manual` | MÃ©todo de gestiÃ³n del recurso |
| `owner` | âœ… SÃ­ | `data-platform`, `{team}` | Equipo propietario |
| `data_format` | ðŸ”¶ Condicional | `parquet`, `avro`, `json` | Formato de datos (para buckets/datasets) |
| `source_system` | ðŸ”¶ Condicional | `qlikview`, `sap`, etc. | Sistema fuente (para pipelines de ingesta) |
| `cost_center` | ðŸ”¶ Opcional | CÃ³digo de centro de costos | Para facturaciÃ³n detallada |

### Checklist de ValidaciÃ³n

Antes de crear cualquier recurso GCP, verificar:

- [ ] El nombre cumple con el patrÃ³n `<empresa>-<plataforma>-<dominio>-<componente>-<entorno>-<region>`
- [ ] La longitud del nombre estÃ¡ dentro de los lÃ­mites del servicio
- [ ] Se usan solo minÃºsculas y guiones (no guiones bajos ni mayÃºsculas)
- [ ] Todas las etiquetas obligatorias estÃ¡n presentes
- [ ] El recurso estÃ¡ documentado en el Data Catalog (si aplica)
- [ ] Existe un owner claramente identificado
- [ ] El recurso se crea vÃ­a Terraform (preferido) o estÃ¡ documentado si es manual
